{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSnUZE4wVJ05",
    "outputId": "626fc421-0655-4966-e690-ee814a6622c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1s64DpxbfRPAjmFdx14ji4RkKPU8KlQge\n",
      "To: /content/data/images_1.5M_250x500.tar.gz\n",
      "3.01GB [01:04, 46.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install gdown\n",
    "rm -rf *\n",
    "mkdir images\n",
    "mkdir data\n",
    "cd data\n",
    "gdown 'https://drive.google.com/uc?id=1s64DpxbfRPAjmFdx14ji4RkKPU8KlQge'\n",
    "tar -xvf images_1.5M_250x500.tar.gz\n",
    "rm -rf images_1.5M_250x500.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Qeg8I6wQDzQ0"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "import gc\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 250\n",
    "        self.img_cols = 500\n",
    "        self.channels = 1\n",
    "        self.img_shape = (250, 500, 1)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        validity = self.discriminator(img)\n",
    "\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "        train_it = tf.keras.preprocessing.image.DirectoryIterator(\n",
    "          directory='data', target_size=(250, 500),\n",
    "          color_mode='grayscale',\n",
    "          batch_size=batch_size,\n",
    "          image_data_generator=ImageDataGenerator(),\n",
    "          shuffle=True\n",
    "        )\n",
    "\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            X_train,_ = train_it.next()\n",
    "            if X_train.shape[0] < batch_size:\n",
    "              train_it = tf.keras.preprocessing.image.DirectoryIterator(\n",
    "                directory='data', target_size=(250, 500),\n",
    "                color_mode='grayscale',\n",
    "                batch_size=batch_size,\n",
    "                image_data_generator=ImageDataGenerator(),\n",
    "                shuffle=True\n",
    "              )\n",
    "              X_train,_ = train_it.next()\n",
    "\n",
    "            X_train = X_train / 127.5 - 1.\n",
    "            X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(X_train, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "            if epoch % 3000 == 0 and epoch > 0:\n",
    "                self.generator.save_weights('dados_generator%d.h5' % (epoch))\n",
    "                self.discriminator.save_weights('dados_discriminator%d.h5' % (epoch))\n",
    "                gc.collect()\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "    def new_sample(self):\n",
    "        noise = np.random.normal(0, 1, (1, self.latent_dim))\n",
    "        return tf.reshape(self.generator.predict(noise)[0], [250,500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pMda5HzUIWJ3",
    "outputId": "c868689f-0be9-490c-e519-17cd0176fcdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 125000)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               64000512  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 64,132,097\n",
      "Trainable params: 64,132,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 125000)            128125000 \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 250, 500, 1)       0         \n",
      "=================================================================\n",
      "Total params: 128,814,920\n",
      "Trainable params: 128,811,336\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "Found 1584663 images belonging to 1 classes.\n",
      "0 [D loss: 0.553907, acc.: 54.69%] [G loss: 0.649512]\n",
      "1 [D loss: 0.317096, acc.: 82.81%] [G loss: 0.520622]\n",
      "2 [D loss: 0.637967, acc.: 54.69%] [G loss: 0.961819]\n",
      "3 [D loss: 0.794704, acc.: 62.50%] [G loss: 2.483178]\n",
      "4 [D loss: 0.704543, acc.: 76.56%] [G loss: 2.632363]\n",
      "5 [D loss: 0.820670, acc.: 60.94%] [G loss: 1.810125]\n",
      "6 [D loss: 0.722544, acc.: 67.19%] [G loss: 2.920060]\n",
      "7 [D loss: 0.726109, acc.: 70.31%] [G loss: 3.471322]\n",
      "8 [D loss: 9.112496, acc.: 17.19%] [G loss: 5.093850]\n",
      "9 [D loss: 6.142519, acc.: 71.88%] [G loss: 11.694591]\n",
      "10 [D loss: 5.528861, acc.: 71.88%] [G loss: 9.872940]\n",
      "11 [D loss: 5.117194, acc.: 75.00%] [G loss: 15.494257]\n",
      "12 [D loss: 10.320556, acc.: 60.94%] [G loss: 8.426798]\n",
      "13 [D loss: 7.276305, acc.: 67.19%] [G loss: 17.855423]\n",
      "14 [D loss: 11.038599, acc.: 68.75%] [G loss: 18.070707]\n",
      "15 [D loss: 5.173275, acc.: 73.44%] [G loss: 13.086433]\n",
      "16 [D loss: 6.614559, acc.: 62.50%] [G loss: 9.965298]\n",
      "17 [D loss: 1.753663, acc.: 68.75%] [G loss: 6.574071]\n",
      "18 [D loss: 0.704296, acc.: 78.12%] [G loss: 9.476164]\n",
      "19 [D loss: 15.351200, acc.: 21.88%] [G loss: 17.301559]\n",
      "20 [D loss: 13.195950, acc.: 68.75%] [G loss: 25.743380]\n",
      "21 [D loss: 12.423069, acc.: 70.31%] [G loss: 29.031324]\n",
      "22 [D loss: 14.887503, acc.: 73.44%] [G loss: 20.242481]\n",
      "23 [D loss: 16.986143, acc.: 67.19%] [G loss: 26.375935]\n",
      "24 [D loss: 18.588736, acc.: 67.19%] [G loss: 23.423292]\n",
      "25 [D loss: 12.506926, acc.: 71.88%] [G loss: 27.259735]\n",
      "26 [D loss: 14.396934, acc.: 71.88%] [G loss: 21.324663]\n",
      "27 [D loss: 14.112722, acc.: 70.31%] [G loss: 23.297832]\n",
      "28 [D loss: 14.470462, acc.: 71.88%] [G loss: 23.919903]\n",
      "29 [D loss: 16.395035, acc.: 67.19%] [G loss: 13.436240]\n",
      "30 [D loss: 10.963071, acc.: 75.00%] [G loss: 10.833746]\n",
      "31 [D loss: 8.574566, acc.: 73.44%] [G loss: 16.602791]\n",
      "32 [D loss: 9.869873, acc.: 68.75%] [G loss: 22.692493]\n",
      "33 [D loss: 9.674711, acc.: 73.44%] [G loss: 14.119205]\n",
      "34 [D loss: 5.709026, acc.: 73.44%] [G loss: 12.303934]\n",
      "35 [D loss: 4.565873, acc.: 67.19%] [G loss: 11.707411]\n",
      "36 [D loss: 2.973932, acc.: 78.12%] [G loss: 9.368672]\n",
      "37 [D loss: 3.044363, acc.: 75.00%] [G loss: 6.980497]\n",
      "38 [D loss: 1.264139, acc.: 78.12%] [G loss: 9.205139]\n",
      "39 [D loss: 0.549998, acc.: 85.94%] [G loss: 8.488844]\n",
      "40 [D loss: 17.189460, acc.: 29.69%] [G loss: 14.672975]\n",
      "41 [D loss: 15.173323, acc.: 71.88%] [G loss: 13.707869]\n",
      "42 [D loss: 12.939664, acc.: 68.75%] [G loss: 13.154384]\n",
      "43 [D loss: 29.684576, acc.: 64.06%] [G loss: 23.058975]\n",
      "44 [D loss: 17.101929, acc.: 70.31%] [G loss: 38.301723]\n",
      "45 [D loss: 25.366758, acc.: 65.62%] [G loss: 29.283810]\n",
      "46 [D loss: 22.254267, acc.: 73.44%] [G loss: 24.415804]\n",
      "47 [D loss: 37.609318, acc.: 62.50%] [G loss: 28.388653]\n",
      "48 [D loss: 22.660480, acc.: 70.31%] [G loss: 21.735899]\n",
      "49 [D loss: 18.284149, acc.: 65.62%] [G loss: 13.999599]\n",
      "50 [D loss: 18.018303, acc.: 68.75%] [G loss: 16.095116]\n",
      "51 [D loss: 7.129296, acc.: 79.69%] [G loss: 16.424158]\n",
      "52 [D loss: 10.923313, acc.: 75.00%] [G loss: 21.714432]\n",
      "53 [D loss: 5.461604, acc.: 75.00%] [G loss: 12.191372]\n",
      "54 [D loss: 2.987936, acc.: 75.00%] [G loss: 12.499537]\n",
      "55 [D loss: 2.781466, acc.: 73.44%] [G loss: 8.241795]\n",
      "56 [D loss: 1.982278, acc.: 76.56%] [G loss: 8.271357]\n",
      "57 [D loss: 0.828163, acc.: 78.12%] [G loss: 11.917713]\n",
      "58 [D loss: 49.761190, acc.: 7.81%] [G loss: 7.601037]\n",
      "59 [D loss: 24.026363, acc.: 64.06%] [G loss: 15.289166]\n",
      "60 [D loss: 24.233719, acc.: 65.62%] [G loss: 24.431461]\n",
      "61 [D loss: 21.856274, acc.: 64.06%] [G loss: 16.530224]\n",
      "62 [D loss: 25.045671, acc.: 67.19%] [G loss: 16.106876]\n",
      "63 [D loss: 28.226650, acc.: 64.06%] [G loss: 31.860367]\n",
      "64 [D loss: 22.305485, acc.: 68.75%] [G loss: 31.971264]\n",
      "65 [D loss: 21.499733, acc.: 67.19%] [G loss: 22.098831]\n",
      "66 [D loss: 24.661282, acc.: 60.94%] [G loss: 13.979218]\n",
      "67 [D loss: 21.466011, acc.: 65.62%] [G loss: 20.497812]\n",
      "68 [D loss: 19.718121, acc.: 68.75%] [G loss: 9.419704]\n",
      "69 [D loss: 11.780838, acc.: 67.19%] [G loss: 17.733114]\n",
      "70 [D loss: 13.974097, acc.: 70.31%] [G loss: 13.247631]\n",
      "71 [D loss: 10.566908, acc.: 70.31%] [G loss: 15.644504]\n",
      "72 [D loss: 11.006083, acc.: 65.62%] [G loss: 17.438560]\n",
      "73 [D loss: 7.337121, acc.: 68.75%] [G loss: 15.827440]\n",
      "74 [D loss: 3.015179, acc.: 71.88%] [G loss: 11.832761]\n",
      "75 [D loss: 0.616707, acc.: 87.50%] [G loss: 15.509674]\n",
      "76 [D loss: 0.271312, acc.: 92.19%] [G loss: 10.944847]\n",
      "77 [D loss: 0.471623, acc.: 90.62%] [G loss: 12.132528]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-60dd13741a47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-28fc9b9beec4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# Train the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "GAN().train(epochs=10000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3i6ETJ0KI8un"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SimpleGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
